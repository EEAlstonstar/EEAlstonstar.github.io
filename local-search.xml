<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Hadoop ——MapReduce 详解</title>
    <link href="/2023/07/12/Hadoop-%E2%80%94%E2%80%94MapReduce-%E8%AF%A6%E8%A7%A3/"/>
    <url>/2023/07/12/Hadoop-%E2%80%94%E2%80%94MapReduce-%E8%AF%A6%E8%A7%A3/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Hadoop 原理简介</title>
    <link href="/2023/07/12/Hadoop%E5%8E%9F%E7%90%86%E7%AE%80%E4%BB%8B/"/>
    <url>/2023/07/12/Hadoop%E5%8E%9F%E7%90%86%E7%AE%80%E4%BB%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="一、Hadoop分类及架构"><a href="#一、Hadoop分类及架构" class="headerlink" title="一、Hadoop分类及架构"></a>一、Hadoop分类及架构</h1><h2 id="1-1-Hadoop分类"><a href="#1-1-Hadoop分类" class="headerlink" title="1.1 Hadoop分类"></a>1.1 Hadoop分类</h2><p>Hadoop 是一个适合大数据的分布式存储和计算平台。</p><p>狭义上说Hadoop就是一个框架平台，广义上讲Hadoop代表大数据的一个技术生态圈，包括很多其他软件框架。狭义的又分1.x版本和2.x版本，当然还有后面的3.x版本。</p><p>本文将会从最简单的1.x开始探讨，然后逐步讨论2.x版本以及Hadoop生态圈。</p><h2 id="1-2-Hadoop核心架构"><a href="#1-2-Hadoop核心架构" class="headerlink" title="1.2 Hadoop核心架构"></a>1.2 Hadoop核心架构</h2><p>首先关于狭义的1.x版本。</p><p><strong>Hadoop&#x3D;Hbase+MapReduce+HDFS</strong></p><p>Hbase：实时分布式数据库</p><p>MapReduce：分布式计算框架</p><p>HDFS：分布式文件系统</p><p>其中，HDFS和MapReduce是Hadoop<em><strong>最重要的两个组件（无论哪个版本）</strong></em>，因此，本文将重点讨论两者原理。</p><hr><h1 id="二、Hadoop核心部分工作原理"><a href="#二、Hadoop核心部分工作原理" class="headerlink" title="二、Hadoop核心部分工作原理"></a>二、Hadoop核心部分工作原理</h1><h2 id="2-1-HDFS原理"><a href="#2-1-HDFS原理" class="headerlink" title="2.1 HDFS原理"></a>2.1 HDFS原理</h2><h3 id="2-1-1-HDFS简介"><a href="#2-1-1-HDFS简介" class="headerlink" title="2.1.1 HDFS简介"></a>2.1.1 HDFS简介</h3><p>HDFS是典型的主从式架构，采用TCP&#x2F;IP通信，具体架构图如下：</p><p><img src="/2023/07/12/Hadoop%E5%8E%9F%E7%90%86%E7%AE%80%E4%BB%8B/image.png" alt="架构图"></p><p><strong>NameNode</strong>：是Master节点（主节点），可以看作是分布式文件系统中的<strong>管理者</strong>，负责管理文件系统的命名空间、集群配置信息和存储块的复制等。包括了文件信息、每一个文件对应的文件块的信息和每一个文件块在DataNode的信息等。</p><p><strong>DataNode</strong>：是Slave节点（从节点），<strong>文件存储的基本单元</strong>，它将Block存储在本地文件系统中，保存了Block的Meta-data，同时周期性地将所有存在的Block信息发送给NameNode。</p><p><strong>Client</strong>：切分文件；访问HDFS；与NameNode交互，获得文件位置信息；与DataNode交互，读取和写入数据。 </p><p><strong>Block</strong>：HDFS中的基本读写单元；HDFS中的文件都是被切割为block（块）进行存储的；这些块被复制到多个DataNode中；块的大小（通常为64MB）和复制的块数量在创建文件时由Client决定。</p><hr><h3 id="2-1-2-HDFS-写入流程"><a href="#2-1-2-HDFS-写入流程" class="headerlink" title="2.1.2 HDFS 写入流程"></a>2.1.2 HDFS 写入流程</h3><p><img src="/2023/07/12/Hadoop%E5%8E%9F%E7%90%86%E7%AE%80%E4%BB%8B/image-1.jpg" alt="写入流程"></p><p><strong>请注意！作为大数据平台搭建者，身份应该是服务者server而非client</strong></p><ol><li><p>用户向Client（客户机）提出请求。例如，需要写入200MB的数据。</p></li><li><p>Client制定计划：将数据按照64MB为块，进行切割；所有的块都保存三份。</p><blockquote><p><em>HDFS具有<strong>高容错性</strong>的特点，通过增加副本的形式，提高容错性。某一个副本丢失以后，可以自动恢复</em></p></blockquote></li><li><p>Client将大文件切分成块（block）</p><blockquote><p><em>HDFS<strong>适合处理大数据</strong>，能够处理数据规模达到GB\TB、甚至PB级别的数据</em></p></blockquote></li><li><p>针对第一个块，Client告诉NameNode（主控节点），请帮助我，将64MB的块复制三份.</p></li><li><p>NameNode告诉Client三个DataNode（数据节点）的地址，并且将它们根据到Client的距离，进行了排序。</p></li><li><p>Client把数据和清单发给第一个DataNode。</p></li><li><p>第一个DataNode将数据复制给第二个DataNode。</p><blockquote><p><em>不适合<strong>低延时数据</strong>访问，比如毫秒级的存储数据，是做不到的</em><br><em>无法高效的对大量小文件进行<strong>存储</strong></em></p></blockquote></li><li><p>第二个DataNode将数据复制给第三个DataNode。</p></li><li><p>如果某一个块的所有数据都已写入，就会向NameNode反馈已完成。</p></li><li><p>对第二个Block，也进行相同的操作。</p><blockquote><p><em>不支持并发写入、文件随机修改。仅支持append（追加）</em></p></blockquote></li><li><p>所有Block都完成后，关闭文件。NameNode会将数据持久化到磁盘上。</p></li></ol><hr><h3 id="2-1-3-HDFS-读取流程"><a href="#2-1-3-HDFS-读取流程" class="headerlink" title="2.1.3 HDFS 读取流程"></a>2.1.3 HDFS 读取流程</h3><p><img src="/2023/07/12/Hadoop%E5%8E%9F%E7%90%86%E7%AE%80%E4%BB%8B/image-2.png" alt="读取流程"></p><ol><li><p>用户向Client提出读取请求。</p></li><li><p>Client向NameNode请求这个文件的所有信息。</p></li><li><p>NameNode将给Client这个文件的块列表，以及存储各个块的数据节点清单（按照和客户端的距离排序）。</p></li><li><p>Client从距离最近的数据节点下载所需的块。</p></li></ol><p><strong>适合一次读入、多次读出的场景，且不支持文件的修改。适合用来做数据分析，非不是网盘应用</strong></p><hr><h2 id="2-2-MapReduce原理"><a href="#2-2-MapReduce原理" class="headerlink" title="2.2 MapReduce原理"></a>2.2 MapReduce原理</h2><h3 id="2-2-1-MapReducd-流程"><a href="#2-2-1-MapReducd-流程" class="headerlink" title="2.2.1 MapReducd 流程"></a>2.2.1 MapReducd 流程</h3><p>再来看看MapReduce</p><p>MapReduce实则是由两个部分构成的，<strong>Map（映射）</strong>和<strong>Reduce（归约）</strong><br>可以说，前者负责”分“，后者负责”合“，这两个机制可以有效帮助不会并行运算的程序员实现并行技术，是一项可靠的，具有容错能力的技术。<br>这个定义中包含5个关键词：</p><ul><li><strong>软件框架</strong></li><li><strong>并行处理</strong></li><li><strong>可靠且容错</strong></li><li><strong>大规模集群</strong></li><li><strong>海量数据集</strong></li></ul><p>当我们向MapReduce提交一个计算作业时，它会首先把计算作业拆分成若干个<strong>Map任务</strong>，然后分配到不同的节点上执行，每一个Map任务处理输入数据中的一部分，当Map任务完成后，<br>它会生成一些中间文件，这些中间文件将会作为<strong>Reduce任务</strong>的输入数据。<br>Reduce任务的主要目标就是<strong>把前面若干个Map的输出汇总到一起并输出。</strong></p><p><strong>请注意！大数据技术解决的主要是海量数据的存储和计算，技术任务中通常包含计算，这与HDFS往往是一同进行的，也就是说，文件传输到Hadoop平台中，会先使用HDFS技术进行存储、切块和备份，正如上文所讲。然后再进行MapReduce计算。这也意味着，MapReduce的input来源于HDFS。</strong></p><p>具体架构图如下：</p><p><img src="/2023/07/12/Hadoop%E5%8E%9F%E7%90%86%E7%AE%80%E4%BB%8B/img.png" alt="MapReduce架构图"></p><p>看来很抽象，举个例子，比如我们需要一个统计文本中的词频工作，其工作图长这样：</p><p><img src="/2023/07/12/Hadoop%E5%8E%9F%E7%90%86%E7%AE%80%E4%BB%8B/img-1.png" alt="词频分析.png"></p><ol><li><p>首先，Hadoop会将输入的数据切成若干个分片，并将每一个分片交给一个map task（Map任务）处理</p><blockquote><p><em>注意，这里的<strong>split</strong>和前文的HDFS中的<strong>block</strong>有极大的不同，split是一个<strong>逻辑概念</strong>，block是一个<strong>物理概念</strong>，默认切片大小与block块相同，因为如果超过block块，可能会产生跨节点的网络io问题</em></p></blockquote></li><li><p>Mapping之后，相当于得到了每一个task里面，每个词以及它出现的次数</p></li><li><p>shuffle（拖移）将相同的词放在一起，并对它们进行排序，分成若干个分片。</p><blockquote><p><em>Map和shuffle概念较为复杂，此处并不详说。详细可看<a href="Hadoop-%E2%80%94%E2%80%94MapReduce-%E8%AF%A6%E8%A7%A3.md">Hadoop之MapReduce 详解</a></em></p></blockquote></li><li><p>根据这些分片，进行reduce（归约）。</p><blockquote><p><em>注意，Reducing阶段中，每一个key调用一次reduce方法，Reduce个数是自己指定的，一个reduce对应一个输出文件</em></p></blockquote></li><li><p>统计出reduce task的结果，输出到文件。</p><blockquote><p><em>正如前文所言，MapReduce是依托HDFS的，所以把数据输出到HDFS上</em></p></blockquote></li></ol><p><strong>简单来说，MapReduce这个框架模型，极大地方便了编程人员在不会分布式并行编程的情况下，将自己的程序运行在分布式系统上</strong></p><hr><h3 id="2-2-2-MapReduce角色"><a href="#2-2-2-MapReduce角色" class="headerlink" title="2.2.2 MapReduce角色"></a>2.2.2 MapReduce角色</h3><p>为了完成上述流程。在MapReduce里，拥有两个角色进行辅助：<strong>JobTracker</strong>以及<strong>TaskTracker</strong><br>严格意义上讲，MapReduce的操作流程是这样的：</p><p><img src="/2023/07/12/Hadoop%E5%8E%9F%E7%90%86%E7%AE%80%E4%BB%8B/img-2.png" alt="img.png"></p><ul><li><strong>JobTracker</strong>：<br>负责调度构成一个作业的所有任务，这些任务分布在不同的TaskTracker上（由上图的JobTracker可以看到2 assign map 和 3 assign reduce）。你可以将其理解为公司的项目经理，项目经理接受项目需求，并划分具体的任务给下面的开发工程师。</li><li><strong>TaskTracker</strong>：<br>TaskTracker负责执行由JobTracker指派的任务，这里我们就可以将其理解为开发工程师，完成项目经理安排的开发任务即可。</li></ul><p><strong>从原理上说，JobTracker从client得到任务，将任务调度给TaskTracker上，然后去client交回任务</strong></p><hr><h1 id="三、Hadoop-1-x版本和2-x版本类同"><a href="#三、Hadoop-1-x版本和2-x版本类同" class="headerlink" title="三、Hadoop 1.x版本和2.x版本类同"></a>三、Hadoop 1.x版本和2.x版本类同</h1><h2 id="2-1-Hadoop的2-x版本"><a href="#2-1-Hadoop的2-x版本" class="headerlink" title="2.1 Hadoop的2.x版本"></a>2.1 Hadoop的2.x版本</h2><p>2011年11月，Hadoop 1.0.0版本正式发布，但存在很多问题：  </p><ol><li>扩展性差，JobTracker负载较重，成为性能瓶颈。</li><li>可靠性差，NameNode只有一个，万一挂掉，整个系统就会崩溃。</li><li>仅适用MapReduce一种计算方式。</li><li>资源管理的效率比较低。</li></ol><p>所以，2012年5月，Hadoop推出了2.0版本，在原本的分工中，MapReduce负责资源管理和计算。在2.x中，在HDFS之上，增加了<strong>YARN（资源管理框架）层</strong>。它是一个资源管理模块，为各类应用程序提供资源管理和调度。</p><p><img src="/2023/07/12/Hadoop%E5%8E%9F%E7%90%86%E7%AE%80%E4%BB%8B/img_3.png" alt="img_1.png"></p><h2 id="2-2-Yarn原理"><a href="#2-2-Yarn原理" class="headerlink" title="2.2 Yarn原理"></a>2.2 Yarn原理</h2><h3 id="2-2-1"><a href="#2-2-1" class="headerlink" title="2.2.1"></a>2.2.1</h3><p>前文提到MapReduce</p><h1 id="四、Hadoop生态圈"><a href="#四、Hadoop生态圈" class="headerlink" title="四、Hadoop生态圈"></a>四、Hadoop生态圈</h1><h2 id="4-1-Hadoop-生态圈"><a href="#4-1-Hadoop-生态圈" class="headerlink" title="4.1 Hadoop 生态圈"></a>4.1 Hadoop 生态圈</h2><p><img src="/2023/07/12/Hadoop%E5%8E%9F%E7%90%86%E7%AE%80%E4%BB%8B/img-10.png" alt="词频分析.png"></p><p>在整个Hadoop架构中，计算框架起到<strong>承上启下</strong>的作用，一方面可以操作HDFS中的数据，另一方面可以被封装，提供Hive、Pig这样的上层组件的调用。</p><p>简单介绍一下其中几个比较重要的组件。</p><p><strong>HBase</strong>：来源于Google的BigTable；是一个高可靠性、高性能、面向列、可伸缩的<strong>分布式数据库</strong>。</p><p><strong>Hiv</strong>e：是一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。</p><p><strong>Pig</strong>：是一个基于Hadoop的大规模数据分析工具，它提供的SQL-LIKE语言叫Pig Latin，该语言的编译器会把类SQL的数据分析请求转换为一系列经过优化处理的MapReduce运算。</p><p><strong>ZooKeeper</strong>：来源于Google的Chubby；它主要是用来解决分布式应用中经常遇到的一些数据管理问题，简化分布式应用协调及其管理的难度。</p><p><strong>Ambari</strong>：Hadoop管理工具，可以快捷地监控、部署、管理集群。</p><p><strong>Sqoop</strong>：用于在Hadoop与传统的数据库间进行数据的传递。</p><p><strong>Mahout</strong>：一个可扩展的机器学习和数据挖掘库。  </p><p>如果还是有点疑惑的话，这张图应当会较为直观：</p><p><img src="/2023/07/12/Hadoop%E5%8E%9F%E7%90%86%E7%AE%80%E4%BB%8B/img-4.png" alt="img.png"></p><p><strong>总的来看，Hadoop有以下优点：</strong></p><ul><li><strong>高可靠性</strong>：这个是由它的基因决定的。它的基因来自Google。Google最擅长的事情，就是“垃圾利用”。Google起家的时候就是穷，买不起高端服务器，所以，特别喜欢在普通电脑上部署这种大型系统。虽然硬件不可靠，但是系统非常可靠。</li><li><strong>高扩展性</strong>：Hadoop是在可用的计算机集群间分配数据并完成计算任务的，这些集群可以方便地进行扩展。说白了，想变大很容易。</li><li><strong>高效性</strong>：Hadoop能够在节点之间动态地移动数据，并保证各个节点的动态平衡，因此处理速度非常快。</li><li><strong>高容错性</strong>：Hadoop能够自动保存数据的多个副本，并且能够自动将失败的任务重新分配。这个其实也算是高可靠性。</li><li><strong>低成本</strong>：Hadoop是开源的，依赖于社区服务，使用成本比较低。</li></ul><p>基于这些优点，Hadoop适合应用于大数据存储和大数据分析的应用，适合于服务器几千台到几万台的集群运行，支持PB级的存储容量。</p><p>Hadoop的应用非常广泛，包括：<strong>搜索、日志处理、推荐系统、数据分析、视频图像分析、数据保存</strong>等，都可以使用它进行部署</p><h1 id="五、Spark简介"><a href="#五、Spark简介" class="headerlink" title="五、Spark简介"></a>五、Spark简介</h1><p>最后，再说说Spark。</p><p><img src="/2023/07/12/Hadoop%E5%8E%9F%E7%90%86%E7%AE%80%E4%BB%8B/img_5.png" alt="img_1.png"></p><p>Spark同样是Apache软件基金会的顶级项目。它可以理解为在Hadoop基础上的一种改进。 它是加州大学伯克利分校AMP<br>实验室所开源的类Hadoop MapReduce的通用并行框架。相对比Hadoop，它可以说是青出于蓝而胜于蓝。</p><p>正如前文所言，MapReduce是面向<strong>磁盘</strong>的。因此，受限于磁盘读写性能的约束，MapReduce在处理迭代计算、实时计算、交互式数据查询等方面并不高效<br>。但是，这些计算却在图计算、数据挖掘和机器学习等相关应用领域中非常常见。</p><p>而Spark是面向<strong>内存</strong>的。这使得Spark能够为多个不同数据源的数据提供近乎<strong>实时</strong>的处理性能，适用于需要多次操作特定数据集的应用场景。</p><p>在相同的实验环境下处理相同的数据，若在内存中运行，那么Spark要比MapReduce快100倍。<br><strong>其它方面，例如处理迭代运算、计算数据分析类报表、排序等，Spark都比MapReduce快很多。</strong></p><p>此外，Spark在易用性、通用性等方面，也比Hadoop更强。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Hadoop</tag>
      
      <tag>大数据</tag>
      
      <tag>实习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>搭建一个基于爬虫功能图像三分类系统</title>
    <link href="/2023/07/12/%E6%90%AD%E5%BB%BA%E5%9F%BA%E4%BA%8E%E7%88%AC%E8%99%AB%E6%8A%80%E6%9C%AF%E7%9A%84%E5%9B%BE%E5%83%8F%E4%B8%89%E5%88%86%E7%B1%BB%E7%B3%BB%E7%BB%9F/"/>
    <url>/2023/07/12/%E6%90%AD%E5%BB%BA%E5%9F%BA%E4%BA%8E%E7%88%AC%E8%99%AB%E6%8A%80%E6%9C%AF%E7%9A%84%E5%9B%BE%E5%83%8F%E4%B8%89%E5%88%86%E7%B1%BB%E7%B3%BB%E7%BB%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="一、功能分析"><a href="#一、功能分析" class="headerlink" title="一、功能分析"></a>一、功能分析</h1><p>整个任务就分成两个大类。一是爬虫技术，二是图像识别。<br>首先是爬虫技术，为了满足其后图像识别的三分类效果，应当设计一个可根据关键词进行搜索的功能。因而最佳的爬取网站就是百度。<br>其次是图像识别，本报告着重应用其图像分类功能。通过搭建神经网络，与划分数据集的方式进行识别。并做一个简单的训练可视化。<br>在确定了根据关键词爬取百度图片+神经网络三分类的基本思路后。再来确定关键的模块化与GUI界面。<br>首先关于模块化、多线程等技术，则任务需要分程序实现，应当有一个主函数以及多个负责爬虫、神经网络识别、GUI窗口的模块。<br>其次是关于图形界面的问题，即GUI窗口。可以使用tkinter包来实现这以功能。为了保证整体美观的效果。也可考虑对GUI窗口进行一定程度上的设计，包括增添背景图片、添加文字说明等。<br>根据上述分析，本任务主要需求为：<br>1.搭建一个可以基于用户的三个关键词进行爬取的爬虫系统。并且设计出有关爬虫的GUI界面；<br>2.归纳整理爬取的数据为数据集。设计程序进行测试集与验证集划分；<br>3.设计一个神经网络进行图像识别分类任务。同时写train与test函数进行验证与训练。可保留训练日志；<br>4.设计一个图像识别相关界面，进行训练可视化。</p><hr><h1 id="二、设计方案与具体细节"><a href="#二、设计方案与具体细节" class="headerlink" title="二、设计方案与具体细节"></a>二、设计方案与具体细节</h1><h2 id="2-1-设计用于爬虫程序读取数据的GUI窗口"><a href="#2-1-设计用于爬虫程序读取数据的GUI窗口" class="headerlink" title="2.1  设计用于爬虫程序读取数据的GUI窗口"></a>2.1  设计用于爬虫程序读取数据的GUI窗口</h2><p>针对爬取图片这一问题，首先我们定义一个图形窗口用来获得用户需求。基于此，我使用python的tkinter包达成这一目的。为了达到我们预想中的GUI界面实现效果，首先要明确的是，为了更方便的从界面中获取数据值，所以我们的变量应当都是全局变量方便调用。基于此，我们分成以下步骤进行实现框架。</p><hr><p>1.在窗口的设计方面；新建Img文件夹，可以制作.ico后缀照片作为窗口样式，背景上可以通过tkinter中的ImageTK.PhotoImage引入自己想要的图片，然后使用place进行放置。<br>‘’’iconPath &#x3D; ‘..\Img\favicon.ico’<br>    window &#x3D; Tk()<br>    window.title(‘python爬虫读取页面’)<br>    image2 &#x3D; Image.open(r’Img\background (2).gif’)<br>    background_image &#x3D; ImageTk.PhotoImage(image2)<br>    w &#x3D; background_image.width()<br>    h &#x3D; background_image.height()<br>    window.geometry(‘%dx%d+0+0’ % (w, h))<br>    background_label &#x3D; Label(window, image&#x3D;background_image)<br>    background_label.place(x&#x3D;0, y&#x3D;0, relwidth&#x3D;1, relheight&#x3D;1)<br>    window.iconbitmap(iconPath)’’’</p><hr><p>2.在窗口的部件设置上；首先必要的是文字提示语与输入框。包括关键词与照片数量、存储文件夹名，可以通过label标签以及Entry输入来实现这一功能。其次是显示爬虫进度的小窗，包括显示爬取的照片数量以及图片地址，可以通过引入treeview这一方法，同时设计column顶部与scrollbar侧边滑动条来使得界面更加美观。最后是启动按钮与退出按钮，可以直接使用button标签来达到这一功能。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">Label(window, text=<span class="hljs-string">&quot;请输入想爬取图片关键词1：&quot;</span>, font=(<span class="hljs-string">&quot;微软雅黑&quot;</span>, <span class="hljs-number">15</span>), fg=<span class="hljs-string">&quot;black&quot;</span>,bg=<span class="hljs-string">&quot;pink&quot;</span>).place(x=<span class="hljs-number">205</span>, y=<span class="hljs-number">0</span>, anchor=NW)<br>label1_input = Entry(window, font=(<span class="hljs-string">&quot;微软雅黑&quot;</span>, <span class="hljs-number">15</span>), width=<span class="hljs-number">5</span>)<br>label1_input.place(x=<span class="hljs-number">455</span>, y=<span class="hljs-number">0</span>)<br>Label(window, text=<span class="hljs-string">&quot;请输入想爬取的图片个数：&quot;</span>, font=(<span class="hljs-string">&quot;微软雅黑&quot;</span>, <span class="hljs-number">15</span>), fg=<span class="hljs-string">&quot;black&quot;</span>, bg=<span class="hljs-string">&quot;pink&quot;</span>).place(x=<span class="hljs-number">525</span>, y=<span class="hljs-number">0</span>)<br>data1_input = Entry(window, font=(<span class="hljs-string">&quot;微软雅黑&quot;</span>, <span class="hljs-number">15</span>), width=<span class="hljs-number">5</span>)<br>data1_input.place(x=<span class="hljs-number">765</span>, y=<span class="hljs-number">0</span>)<br>Label(window, text=<span class="hljs-string">&quot;请输入存储文件夹：&quot;</span>, font=(<span class="hljs-string">&quot;微软雅黑&quot;</span>, <span class="hljs-number">15</span>), fg=<span class="hljs-string">&quot;black&quot;</span>, bg=<span class="hljs-string">&quot;pink&quot;</span>).place(x=<span class="hljs-number">835</span>, y=<span class="hljs-number">0</span>)<br>location1_input = Entry(window, font=(<span class="hljs-string">&quot;微软雅黑&quot;</span>, <span class="hljs-number">15</span>), width=<span class="hljs-number">5</span>)<br>location1_input.place(x=<span class="hljs-number">1020</span>, y=<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">treeview_width = w - <span class="hljs-number">40</span><br>treeview_height = h / <span class="hljs-number">2</span> - <span class="hljs-number">30</span><br><span class="hljs-keyword">global</span> tree<br>tree = ttk.Treeview(window, height=<span class="hljs-number">10</span>, show=<span class="hljs-string">&#x27;headings&#x27;</span>, selectmode=<span class="hljs-string">&#x27;browse&#x27;</span>,<br>                        takefocus=<span class="hljs-literal">True</span>,columns=(<span class="hljs-string">&quot;totalCount&quot;</span>, <span class="hljs-string">&quot;Name&quot;</span>))<br>tree.column(<span class="hljs-string">&quot;totalCount&quot;</span>, width=<span class="hljs-built_in">int</span>(treeview_width * <span class="hljs-number">0.1</span>))<br>tree.column(<span class="hljs-string">&quot;Name&quot;</span>, width=<span class="hljs-built_in">int</span>(treeview_width * <span class="hljs-number">0.9</span>))<br>tree.heading(<span class="hljs-string">&quot;totalCount&quot;</span>, text=<span class="hljs-string">&quot;序号&quot;</span>,command=<span class="hljs-keyword">lambda</span> c=<span class="hljs-string">&quot;totalCount&quot;</span>:treeview_sort_column(tree, c, <span class="hljs-literal">False</span>, <span class="hljs-string">&#x27;float&#x27;</span>))<br>tree.heading(<span class="hljs-string">&quot;Name&quot;</span>, text=<span class="hljs-string">&quot;图片地址&quot;</span>, command=<span class="hljs-keyword">lambda</span> c=<span class="hljs-string">&quot;Name&quot;</span>:treeview_sort_column(tree, c, <span class="hljs-literal">False</span>, <span class="hljs-string">&#x27;str&#x27;</span>))<br>yscroll = Scrollbar(tree, orient=VERTICAL)<br>yscroll[<span class="hljs-string">&#x27;command&#x27;</span>] = tree.yview<br>yscroll.pack(side=RIGHT, fill=BOTH)<br>tree[<span class="hljs-string">&#x27;yscrollcommand&#x27;</span>] = yscroll.<span class="hljs-built_in">set</span><br>tree.place(x=<span class="hljs-number">10</span>, y=<span class="hljs-number">20</span> + h / <span class="hljs-number">2</span>, width=treeview_width, height=treeview_height)<br></code></pre></td></tr></table></figure><hr><p>3.“开始下载”与“结束”的按钮设计.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">button1 = Button(window, text=<span class="hljs-string">&quot;开始下载&quot;</span>, font=(<span class="hljs-string">&quot;微软雅黑&quot;</span>, <span class="hljs-number">15</span>),<br>                     command=crawler_content).place(x=<span class="hljs-number">580</span>, y=<span class="hljs-number">95</span>)<br>button2 = Button(window, text=<span class="hljs-string">&quot;分类（请运行network程序）&quot;</span>, font=(<span class="hljs-string">&quot;微软雅黑&quot;</span>, <span class="hljs-number">15</span>),<br>                     command=window.quit).place(x=<span class="hljs-number">500</span>, y=<span class="hljs-number">145</span>)<br>window.mainloop()<br></code></pre></td></tr></table></figure><h2 id="2-2-爬虫主函数实现"><a href="#2-2-爬虫主函数实现" class="headerlink" title="2.2 爬虫主函数实现"></a>2.2 爬虫主函数实现</h2><p>上文的button1的(<code>commend= crawler_content</code>)这一功能实际上是在执行名为crawler_content的函数。这是爬虫实现的主函数，主要功能是得到GUI窗口的关键词、图片数量、文件夹名字等数据。并且运行“crawler”模块实现下载和获取推荐词的功能。  </p>]]></content>
    
    
    
    <tags>
      
      <tag>CV</tag>
      
      <tag>爬虫</tag>
      
      <tag>GUI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2023/07/12/hello-world/"/>
    <url>/2023/07/12/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
